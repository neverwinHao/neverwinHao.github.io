<!DOCTYPE html>

<HTML>
<HEAD>
  <META content="IE=5.0000" http-equiv="X-UA-Compatible">
  <META name="description" content="Hao Liu's home page"> 
  <META http-equiv="Content-Type" content="text/html; charset=gb2312">
  <LINK href="files/doc.css" 
    rel="stylesheet" type="text/css"> 
  <TITLE>HaoLiu 刘浩</TITLE> 
  <META name="GENERATOR" content="MSHTML 11.00.10570.1001">
</HEAD>


<BODY> 
  <DIV id="layout-content" style="margin-top: 25px;">
  <TABLE>
    <TBODY>
    <TR>
      <TD width="670">
        <DIV id="toptitle">
        <H1>Hao Liu &nbsp;</H1></DIV>
        <H3>B.S. candidate</H3>
        <P>No.72, Binhai Road, Aoshanwei Street
        <BR>School of Information Science and Engineering
        <BR>Shandong University
        <BR>Qingdao, China, 266237.
        <BR>
        <BR> Email:  
        <A href="mailto:haoliu@mails.sdu.edu.cn"> haoliu@mails.sdu.edu.cn</A>; 
        <BR> Github: 
        <A href="https://github.com/neverwinHao">https://github.com/neverwinHao</A>;
        <!-- <BR> Google scholar:
        <A href="https://scholar.google.com.hk/citations?user=DuetWVcAAAAJ&hl=zh-CN&oi=ao">https://scholar.google.com</A> -->
        <BR><BR></P>
      </TD>
      <TD>
        <IMG width="300" src="files/susu.jpg" border="0">
      </TD>
    </TR>
    <TR></TR></TBODY>
  </TABLE>
  <DIV id="layout-content" style="margin-top: 25px;">


  <H2>Biography</H2>
  <P> I am a B.S. candidate of ChongXin College in the School of Information Science and Engineering</A>, 
    <A href="https://www.ise.sdu.edu.cn/">Shandong University </A>, 
    advised by <A href="https://faculty.sdu.edu.cn/yangyang/zh_CN/index.htm">Prof. Yang Yang</A>.   
  </P>

  <P>My research interests include computer vision and deep learning, specifically for representation learning and multimodal learning.</P>


  <H2>Publications</H2>
    <table class="pub_table">
    <!-- <tbody> -->

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/WNetnew.png" class="papericon"></td>
        <td 
          class="pub_td2"><u>HaoLiu</u>, Yang Yang, Yunxia Liu
          <br><b>W-Net: A Facial Feature-Guided Face Super-Resolution Network</b>
          <br>
          [<a href="https://arxiv.org/pdf/2406.00676">Paper</a>]
          [<a href="https://track.authorhub.elsevier.com?uuid=89d22288-9fc0-4016-a68f-7995d9766a17">Under Review</a>]
          <br>
        </td>
      </tr>

      <!-- <tr>
        <td class="pub_td1"><img src="files/PaperFig/vheat.png" class="papericon"></td>
        <td 
          class="pub_td2">Zhaozhi Wang, Yue Liu, Yunfan Liu, Hongtian Yu, Yaowei Wang, Qixiang Ye, <u>Yunjie Tian</u>
          <br><b>vHeat: Building Vision Models upon Heat Conduction</b>
          <br>
          [<a href="https://arxiv.org/abs/2405.16555">Paper</a>]
          [<a href="https://github.com/MzeroMiko/vHeat">Code</a>]
          <br>
        </td>
      </tr>
      

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/clawmachine.png" class="papericon"></td>
        <td 
          class="pub_td2">Tianren Ma, Lingxi Xie, <u>Yunjie Tian</u>, Boyu Yang, Yuan Zhang, David Doermann, Qixiang Ye
          <br><b>ClawMachine: Fetching Visual Tokens as An Entity for Referring and Grounding</b>
          <br>
          [<a href="https://arxiv.org/abs/2406.11327">Paper</a>]
          [<a href="https://github.com/martian422/ClawMachine">Code</a>]
          <br>
        </td>
      </tr>

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/chatterbox.png" class="papericon"></td>
        <td 
          class="pub_td2"><u>Yunjie Tian</u>, Tianren Ma, Lingxi Xie, Jihao Qiu, Xi Tang, Yuan Zhang, Jianbin Jiao, Qi Tian, Qixiang Ye
          <br><b>ChatterBox: Multi-round Multimidal Referring and Grounding</b>
          <br>
          [<a href="https://arxiv.org/pdf/2401.13307.pdf">Paper</a>]
          [<a href="https://github.com/sunsmarterjie/ChatterBox">Code</a>]
          <br>
        </td>
      </tr>

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/vmamba.png" class="papericon"></td>
        <td 
          class="pub_td2">Yue Liu, <u>Yunjie Tian</u>, Yuzhong Zhao, Hongtian Yu, Lingxi Xie, Yaowei Wang, Qixiang Ye, Yunfan Liu
          <br><b>VMamba: Visual State Space Model</b>
          <br>
          [<a href="https://arxiv.org/abs/2401.10166">Paper</a>]
          [<a href="https://github.com/MzeroMiko/VMamba">Code</a>]
          <br>
        </td>
      </tr>

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/fast_itpn.png" class="papericon"></td>
        <td 
          class="pub_td2"><u>Yunjie Tian</u>, Lingxi Xie, Jihao Qiu, Jianbin Jiao, Qi Tian, Qixiang Ye
          <br><b>Fast-iTPN: Integrally Pre-Trained Transformer Pyramid Network with Token Migration</b>
          <br>TPAMI, 2024
          <br>
          [<a href="https://arxiv.org/abs/2211.12735">Paper</a>]
          [<a href="https://github.com/sunsmarterjie/iTPN/tree/main/fast_itpn">Code</a>]
          <br>
        </td>
      </tr>


      <tr>
        <td class="pub_td1"><img src="files/PaperFig/ifnas.png" class="papericon"></td>
        <td 
          class="pub_td2"><u>Yunjie Tian</u>, Lingxi Xie, Jiemin Fang, Jianbin Jiao, Qixiang Ye, Qi Tian
          <br><b>Exploring Complicated Search Spaces with Interleaving-Free Sampling</b>
          <br>TNNLS, 2024
          <br>
          [<a href="https://arxiv.org/abs/2112.02488">Paper</a>]
          <br>
        </td>
      </tr>

      
      
      <tr>
        <td class="pub_td1"><img src="files/PaperFig/std.png" class="papericon"></td>
        <td 
          class="pub_td2">&ast;Hongtian Yu, &ast;<u>Yunjie Tian</u>, Qixiang Ye, Yunfan Liu
          <br><b>Spatial Transform Decoupling for Oriented Object Detection</b>
          <br>AAAI, 2024
          <br>
          [<a href="https://arxiv.org/abs/2308.10561">Paper</a>]
          [<a href="https://github.com/yuhongtian17/Spatial-Transform-Decoupling">Code</a>]
          <br>
        </td>
      </tr>

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/itpn.png" class="papericon"></td>
        <td 
          class="pub_td2"><u>Yunjie Tian</u>, Lingxi Xie, Zhaozhi Wang, Longhui Wei, Xiaopeng Zhang, Jianbin Jiao, Qi Tian, Qixiang Ye
          <br><b>Integragrally Pre-Trained Transformer Pyramid Networks</b>
          <br>CVPR, 2023
          <br>
          [<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Tian_Integrally_Pre-Trained_Transformer_Pyramid_Networks_CVPR_2023_paper.pdf">Paper</a>]
          [<a href="https://www.bilibili.com/video/BV18L411m7jU/?spm_id_from=333.337.search-card.all.click">Pre.</a>]
          [<a href="https://github.com/sunsmarterjie/iTPN">Code</a>]
          <br>
        </td>
      </tr>

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/hivit.png" class="papericon"></td>
        <td 
          class="pub_td2">&ast;Xiaosong Zhang, &ast;<u>Yunjie Tian</u>, Lingxi Xie, Wei Huang, Qi Dai, Qixiang Ye, Qi Tian
          <br><b>HiViT: A Simpler and More Efficient Design of Hierarchical Vision Transformer</b>
          <br>ICLR, 2023
          <br>
          [<a href="https://openreview.net/forum?id=3F6I-0-57SC">Paper</a>]
          [<a href="https://github.com/zhangxiaosong18/hivit">Code</a>]
          [<a href="https://arxiv.org/abs/2205.14949">arXiv preprint</a>]
          <br>
        </td>
      </tr>

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/beyond_masking.png" class="papericon"></td>
        <td 
          class="pub_td2"><u>Yunjie Tian</u>, Lingxi Xie, Mengnan Shi, Jiemin Fang, Xiaopeng Zhang, Jianbin Jiao, Qi Tian, Qixiang Ye
          <br><b>Beyond Masking: Demystifying Token-Based Pre-Training for Vision Transformers</b>
          <br>
          [<a href="https://arxiv.org/abs/2203.14313">Paper</a>]
          [<a href="https://github.com/sunsmarterjie/beyond_masking">Code</a>]
          <br>
        </td>
      </tr>

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/graformer.png" class="papericon"></td>
        <td 
          class="pub_td2"> Weixi Zhao, Weiqiang Wang, <u>Yunjie Tian</u>
          <br><b>GraFormer: Graph-Oriented Transformer for 3D Pose Estimation</b>
          <br> CVPR, 2022
          <br>
          [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_GraFormer_Graph-Oriented_Transformer_for_3D_Pose_Estimation_CVPR_2022_paper.pdf">Paper</a>]
          [<a href="https://github.com/Graformer/GraFormer">Code</a>]
        </td>
      </tr>

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/daas.png" class="papericon"></td>
        <td 
          class="pub_td2"><u>Yunjie Tian</u>, Chang Liu, Lingxie Xie, Qixiang Ye
          <br><b>Discretization-Aware Architecture Search</b>
          <br> Pattern Recognition, 2021
          <br>
          [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320321003733">Paper</a>]
          [<a href="https://github.com/sunsmarterjie/DAAS">Code</a>]
        </td>
      </tr>

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/sage.png" class="papericon"></td>
        <td 
          class="pub_td2"> <u>Yunjie Tian</u>, Lingxi Xie, Xiaopeng Zhang, Jiemin Fang, Haohang Xu, Wei Huang, Jianbin Jiao, Qi Tian, Qixiang Ye
          <br><b>Semantic-Aware Generation for Self-Supervised Visual Representation Learning</b>
          <br>
          [<a href="https://arxiv.org/pdf/2111.13163.pdf">Paper</a>]
          [<a href="https://github.com/sunsmarterjie/SaGe">Code</a>]
        </td>
      </tr>

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/adalsn.png" class="papericon"></td>
        <td 
          class="pub_td2">&ast;Chang Liu, &ast;<u>Yunjie Tian</u>, Zhiwen Chen, Jianbin Jiao, Qixiang Ye
          <br><b>Adaptive Linear Span Network for Object Skeleton Detection</b>
          <br> TIP, 2021
          <br>
          [<a href="https://arxiv.org/pdf/2011.03972.pdf">arXiv preprint</a>]
          [<a href="https://github.com/sunsmarterjie/SDL-Skeleton">Code</a>]
        </td>
      </tr>


      <tr>
        <td class="pub_td1"><img src="files/PaperFig/gff.png" class="papericon"></td>
        <td 
          class="pub_td2">Yang Qiao, <u>Yunjie Tian</u>, Yue Liu, Jianbin Jiao
          <br><b>Genetic Feature Fusion for Object Skeleton Detection</b>
          <br>Security and Communication Networks, 2021
          <br>
          [<a href="https://www.hindawi.com/journals/scn/2021/6621760/">Paper</a>]
          <br>
        </td>
      </tr> -->

    <!-- </tbody> -->
    </table>

    <H2>Awards</H2>
    <table class="pub_table">
    <!-- <tbody> -->

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/Car.jpg" class="papericon"></td>
        <td 
          class="pub_td2"><u>HaoLiu</u>, Yi Chi, LingTao Zhou, Jiajin Lu, Xiaojie Chen
          <br><b>Second Prize of Undergraduate Intelligent Vehicle Competition National</b>
          <br>
          [<a href="https://arxiv.org/pdf/2406.00676">Patent</a>]
          [<a href="https://github.com/neverwinHao/dataset">Demo</a>]
          <br>
        </td>
      </tr>


    <!-- </tbody> -->
    </table>
  
  <br> <br> 
  <H2>Statistics</H2>
  <script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=5063gq35g0n&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=33" async="async"></script>

</BODY>
</HTML>
